{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacao de bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configuração do Spark para se conectar ao cluster Spark no contêiner\n",
    "#.master(\"spark://spark:7077\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"labdados_transformation\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verifica a versão do Spark para confirmar a conexão\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo do diretório de notebooks: ['.ipynb_checkpoints', 'exploracao_spark.ipynb', 'output']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verificar o conteúdo do diretório /home/jovyan/work\n",
    "notebooks_dir = '/home/jovyan/work'\n",
    "print(\"Conteúdo do diretório de notebooks:\", os.listdir(notebooks_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo do diretório datalake: ['datascience_20241102.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verifique o diretório onde o arquivo JSON deveria estar\n",
    "datalake_dir = '/datalake/twitter_datascience/extract_date=2024-11-02'\n",
    "print(\"Conteúdo do diretório datalake:\", os.listdir(datalake_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leitura de dados\n",
    "\n",
    "json_path = '/datalake/twitter_datascience/extract_date=2024-11-02/datascience_20241102.json'\n",
    "df = spark.read.json(json_path)\n",
    "\n",
    "# Coluna adicional para dados seguirem o padrao definido no curso\n",
    "df = df.withColumn(\"extract_date\", sf.to_date(sf.lit(\"2024-11-02\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+------------+\n",
      "|                data|            includes|              meta|extract_date|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "|[{4, 63, 2024-11-...|{[{2024-11-02T23:...|{1234567890abcdef}|  2024-11-02|\n",
      "|[{30, 16, 2024-11...|{[{2024-11-02T16:...|              NULL|  2024-11-02|\n",
      "|[{85, 46, 2024-11...|{[{2024-11-02T04:...|              NULL|  2024-11-02|\n",
      "|[{23, 25, 2024-11...|{[{2024-11-02T19:...|{1234567890abcdef}|  2024-11-02|\n",
      "|[{35, 48, 2024-11...|{[{2024-11-02T22:...|              NULL|  2024-11-02|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|col                                                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{4, 63, 2024-11-02T17:53:55.931233+0000, [71], 61, 18, en, {70, 19, 72, 70}, Tweet fictício criado usando inteligência artificial para falar sobre data engineer}|\n",
      "|{15, 84, 2024-11-02T00:53:24.440670+0000, [49], 47, 66, en, {26, 46, 78, 88}, Este é um tweet fictício sobre data engineer}                                      |\n",
      "|{27, 96, 2024-11-02T08:54:53.556819+0000, [58], 22, 7, en, {7, 65, 60, 33}, Este é um tweet fictício sobre data engineer}                                        |\n",
      "|{6, 94, 2024-11-02T17:18:14.158636+0000, [88], 81, 83, en, {42, 62, 61, 37}, Outro tweet fictício relacionado a data engineer}                                   |\n",
      "|{35, 57, 2024-11-02T07:44:13.404740+0000, [22], 0, 51, en, {41, 31, 73, 37}, Este é um tweet fictício sobre data engineer}                                       |\n",
      "|{57, 48, 2024-11-02T23:23:04.228079+0000, [92], 63, 51, en, {9, 5, 90, 40}, Outro tweet fictício relacionado a data engineer}                                    |\n",
      "|{97, 77, 2024-11-02T20:52:33.759821+0000, [6], 87, 43, en, {87, 49, 7, 40}, Um terceiro tweet fictício sobre data engineer}                                      |\n",
      "|{4, 58, 2024-11-02T17:43:44.671697+0000, [66], 78, 76, en, {81, 48, 73, 70}, Tweet fictício gerado automaticamente sobre data engineer}                          |\n",
      "|{90, 70, 2024-11-02T10:29:37.131124+0000, [71], 50, 8, en, {91, 5, 43, 80}, Um terceiro tweet fictício sobre data engineer}                                      |\n",
      "|{4, 45, 2024-11-02T12:05:10.143196+0000, [70], 33, 13, en, {34, 39, 87, 51}, Tweet fictício gerado automaticamente sobre data engineer}                          |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_explode = df.select(sf.explode(df.data))\n",
    "\n",
    "data_explode.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-------------------------------+---+----------+-----------+-----------+-------------+-----------------------------------------------------------------------------------+\n",
      "|author_id|conversation_id|created_at                     |id |like_count|quote_count|reply_count|retweet_count|text                                                                               |\n",
      "+---------+---------------+-------------------------------+---+----------+-----------+-----------+-------------+-----------------------------------------------------------------------------------+\n",
      "|4        |63             |2024-11-02T17:53:55.931233+0000|61 |70        |19         |72         |70           |Tweet fictício criado usando inteligência artificial para falar sobre data engineer|\n",
      "|15       |84             |2024-11-02T00:53:24.440670+0000|47 |26        |46         |78         |88           |Este é um tweet fictício sobre data engineer                                       |\n",
      "|27       |96             |2024-11-02T08:54:53.556819+0000|22 |7         |65         |60         |33           |Este é um tweet fictício sobre data engineer                                       |\n",
      "|6        |94             |2024-11-02T17:18:14.158636+0000|81 |42        |62         |61         |37           |Outro tweet fictício relacionado a data engineer                                   |\n",
      "|35       |57             |2024-11-02T07:44:13.404740+0000|0  |41        |31         |73         |37           |Este é um tweet fictício sobre data engineer                                       |\n",
      "|57       |48             |2024-11-02T23:23:04.228079+0000|63 |9         |5          |90         |40           |Outro tweet fictício relacionado a data engineer                                   |\n",
      "|97       |77             |2024-11-02T20:52:33.759821+0000|87 |87        |49         |7          |40           |Um terceiro tweet fictício sobre data engineer                                     |\n",
      "|4        |58             |2024-11-02T17:43:44.671697+0000|78 |81        |48         |73         |70           |Tweet fictício gerado automaticamente sobre data engineer                          |\n",
      "|90       |70             |2024-11-02T10:29:37.131124+0000|50 |91        |5          |43         |80           |Um terceiro tweet fictício sobre data engineer                                     |\n",
      "|4        |45             |2024-11-02T12:05:10.143196+0000|33 |34        |39         |87         |51           |Tweet fictício gerado automaticamente sobre data engineer                          |\n",
      "+---------+---------------+-------------------------------+---+----------+-----------+-----------+-------------+-----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet = df.select(sf.explode(df.data).alias('tweet'))\\\n",
    "    .select('tweet.author_id', 'tweet.conversation_id', 'tweet.created_at',\n",
    "            'tweet.id', 'tweet.public_metrics.*', 'tweet.text')\n",
    "\n",
    "tweet.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "|user                                                  |\n",
      "+------------------------------------------------------+\n",
      "|{2024-11-02T23:44:24.405905+0000, 90, User 1, user1}  |\n",
      "|{2024-11-02T19:20:32.612742+0000, 46, User 2, user2}  |\n",
      "|{2024-11-02T17:19:27.159242+0000, 28, User 3, user3}  |\n",
      "|{2024-11-02T15:12:08.011115+0000, 34, User 4, user4}  |\n",
      "|{2024-11-02T04:46:41.478867+0000, 41, User 5, user5}  |\n",
      "|{2024-11-02T22:58:40.410548+0000, 72, User 6, user6}  |\n",
      "|{2024-11-02T03:25:31.390233+0000, 70, User 7, user7}  |\n",
      "|{2024-11-02T17:16:57.134988+0000, 16, User 8, user8}  |\n",
      "|{2024-11-02T19:44:02.445211+0000, 12, User 9, user9}  |\n",
      "|{2024-11-02T21:04:05.250260+0000, 24, User 10, user10}|\n",
      "+------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_explode = df.select(sf.explode(df.includes.users).alias('user'))\n",
    "\n",
    "data_explode.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+---+-------+--------+\n",
      "|created_at                     |id |name   |username|\n",
      "+-------------------------------+---+-------+--------+\n",
      "|2024-11-02T23:44:24.405905+0000|90 |User 1 |user1   |\n",
      "|2024-11-02T19:20:32.612742+0000|46 |User 2 |user2   |\n",
      "|2024-11-02T17:19:27.159242+0000|28 |User 3 |user3   |\n",
      "|2024-11-02T15:12:08.011115+0000|34 |User 4 |user4   |\n",
      "|2024-11-02T04:46:41.478867+0000|41 |User 5 |user5   |\n",
      "|2024-11-02T22:58:40.410548+0000|72 |User 6 |user6   |\n",
      "|2024-11-02T03:25:31.390233+0000|70 |User 7 |user7   |\n",
      "|2024-11-02T17:16:57.134988+0000|16 |User 8 |user8   |\n",
      "|2024-11-02T19:44:02.445211+0000|12 |User 9 |user9   |\n",
      "|2024-11-02T21:04:05.250260+0000|24 |User 10|user10  |\n",
      "+-------------------------------+---+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user = df.select(sf.explode(df.includes.users).alias('user'))\\\n",
    "    .select('user.created_at', 'user.id', 'user.name', 'user.username')\n",
    "\n",
    "user.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.coalesce(1).write.mode(\"overwrite\").json('output/tweet')\n",
    "user.coalesce(1).write.mode('overwrite').json('output/user')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
